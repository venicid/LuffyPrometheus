# 单机版安装教程
> 1.过程
- 依赖文件 `m3dbnode` `m3dbnode.service`  `m3dbnode_single.yaml` 
- 执行 `m3db_single_install.sh`
- 实战，未实现。服务启动失败
- m3_1.1.0_linux_amd64, 试试这个版本的


```yaml
# 内存消耗至少2个G，比较大

# 实战1：单机版本
# 参考blog，但是，过了一会自动挂掉
https://blog.csdn.net/alien__pass/article/details/116596961


# 实战2：官网docker启动
# 注意：要去k8s的机器上面
https://m3db.io/docs/quickstart/docker/

docker run -p 7201:7201 -p 7203:7203 --name m3db -v $(pwd)/m3db_data:/var/lib/m3db quay.io/m3db/m3dbnode:v1.1.0
```

> 2. 测试m3db
```shell

# 创建namespace和placement
curl -X POST http://localhost:7201/api/v1/database/create -d '{
  "type": "local",
  "namespaceName": "default",
  "retentionTime": "48h",
  "numShards": "8"
}'

# 查看初始化状态
curl http://localhost:7201/api/v1/services/m3db/placement  |python -m json.tool
# ready一下

#!/bin/bash
curl -X POST http://localhost:7201/api/v1/services/m3db/namespace/ready -d '{
  "name": "default"
}'

# 写入测试数据
#!/bin/bash
curl -X POST http://localhost:7201/api/v1/json/write -d '{
  "tags":
    {
      "__name__": "third_avenue",
      "city": "new_york",
      "checkout": "1"
    },
    "timestamp": '\"$(date "+%s")\"',
    "value": 3347.26
}'
# 查询测试数据

curl -X "POST" -G "http://localhost:7201/api/v1/query_range" \
  -d "query=third_avenue" \
  -d "start=$(date "+%s" -d "45 seconds ago")" \
  -d "end=$( date +%s )" \
  -d "step=5s"
```

> 3. 和prometheus整合

```shell script
# 在prometheus.yml 添加remote_read/write 段即可
remote_write:
  - url: "http://192.168.116.133:7201/api/v1/prom/remote/write"
remote_read:
  - url: "http://192.168.116.133:7201/api/v1/prom/remote/read"
    read_recent: true

# 重启
[root@prome-master01 ~]# systemctl restart prometheus

# 在m3dnode上抓包查看，需要到容器内部查看
tcpdump -i any tcp dst port 9000 -nn -vv -p -A

# 查看m3db的data
/var/lib/m3db/data/default # pwd
/var/lib/m3db/data/default
# ls |wc -l
64
```

# 找一个prometheus只做 query ，remote_read m3coor
- 去node1节点的Prometheus
- prometheus.yml，备份原文件，删除scrape_configs
```shell script
remote_read:
  - url: "http://192.168.116.133:7201/api/v1/prom/remote/read"
    read_recent: true
```
- 重启,查询测试
```yaml
# node2的prome查询， 没有补全，远端查询
node_cpu_seconds_total
```

> 注意事项
- 单机版内嵌了etcd进程，如果测试机上有etcd的需要注意下端口冲突
- `m3dbnode`可以选择是否开启内嵌的`m3coordinator`

> m3db解读
```yaml
# 4大组件，内嵌入
[root@prome-master01 tgzs]# cd m3_1.1.0_linux_amd64
[root@prome-master01 m3_1.1.0_linux_amd64]# ll
total 216096
-rw-r--r-- 1 root nobody    11357 Feb  4  2021 LICENSE
-rwxr-xr-x 1 root root   40661123 Feb  4  2021 m3aggregator
-rwxr-xr-x 1 root root   56874999 Feb  4  2021 m3coordinator
-rwxr-xr-x 1 root root   66842617 Feb  4  2021 m3dbnode
-rwxr-xr-x 1 root root   56874999 Feb  4  2021 m3query
-rw-r--r-- 1 root nobody     5154 Feb  4  2021 README.md

/var/lib/m3db/data/default # netstat -nlpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 :::7201                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::7203                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::9000                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::9001                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::9002                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::9003                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::2379                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::9004                 :::*                    LISTEN      1/m3dbnode
tcp        0      0 :::2380                 :::*                    LISTEN      1/m3dbnod

# metrics
http://192.168.116.133:7203/metrics
# docker 需要把端口映射添加
http://192.168.116.133:9004/metrics

# prometheus采集m3db
  - job_name: 'm3db'
    honor_timestamps: true
    scrape_interval: 15s
    scrape_timeout: 10s
    metrics_path: /metrics
    scheme: http
    static_configs:
    - targets:
      - 192.168.116.133:7203
      - 192.168.116.133:9004
  
# 查看
coordinator_http_handler_http_handler_latency_bucket


# 分片与副本数量 影响size
  
# 内存占用
  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                   
  5854 root      20   0   13.9g   2.5g  32600 S  26.2 32.1  29:01.03 m3dbnode

# 文档
https://m3db.io/docs/operational_guide/replication_and_deployment_in_zones/
https://m3db.io/docs/operational_guide/placement_configuration/

Number of Nodes	Number of Shards
3	64
6	128
12	256
24	512
48	1024
128+	4096
```







> 配置文件解读
```yaml


# 是否开启内嵌的 M3Coordinator
coordinator:
  # Address for M3Coordinator to listen for traffic.
  listenAddress: 0.0.0.0:7201
  # 所有m3db namespace(理解为表)都必须列在这里，
  # 如果少了则读写丢数据
  # All configured M3DB namespaces must be listed in this config if running an
  # embedded M3Coordinator instance.
  local:
    namespaces:
      - namespace: default
        type: unaggregated
        retention: 48h

  # M3Coordinator 日志
  logging:
    level: info

  # M3Coordinator metric
  metrics:
    scope:
      # Prefix to apply to all metrics.
      prefix: "coordinator"
    prometheus:
      # Path and address to expose Prometheus scrape endpoint.
      handlerPath: /metrics
      listenAddress: 0.0.0.0:7203 # until https://github.com/m3db/m3/issues/682 is resolved
    sanitization: prometheus
    # Sampling rate for metrics, use 1.0 for no sampling.
    samplingRate: 1.0
    extended: none

  tagOptions:
    # Configuration setting for generating metric IDs from tags.
    idScheme: quoted

db:
  # Minimum log level which will be emitted.
  logging:
    level: info

  # Configuration for emitting M3DB metrics.
  metrics:
    prometheus:
      # Path to expose Prometheus scrape endpoint.
      handlerPath: /metrics
    sanitization: prometheus
    # Sampling rate for metrics, use 1.0 for no sampling.
    samplingRate: 1.0
    extended: detailed

  # 9000 是本实例的 thrift/tchannel接收数据接口
  # Address to listen on for local thrift/tchannel APIs.
  listenAddress: 0.0.0.0:9000
  # 9001 是集群间实例的 thrift/tchannel接收数据接口
  # Address to listen on for cluster thrift/tchannel APIs.
  clusterListenAddress: 0.0.0.0:9001
  # 9002 是本实例的json/http接口 (主要用来debug)
  # Address to listen on for local json/http APIs (used for debugging primarily).
  httpNodeListenAddress: 0.0.0.0:9002
  # Address to listen on for cluster json/http APIs (used for debugging primarily).
  httpClusterListenAddress: 0.0.0.0:9003
  # Address to listen on for debug APIs (pprof, etc).
  debugListenAddress: 0.0.0.0:9004

  # Configuration for resolving the instances host ID.
  hostID:
    # "Config" resolver states that the host ID will be resolved from this file.
    resolver: config
    value: m3db_local

  client:
    # Consistency level for writes.
    writeConsistencyLevel: majority
    # Consistency level for reads.
    readConsistencyLevel: unstrict_majority
    # Timeout for writes.
    writeTimeout: 10s
    # Timeout for reads.
    fetchTimeout: 15s
    # Timeout for establishing a connection to the cluster.
    connectTimeout: 20s
    # Configuration for retrying writes.
    writeRetry:
        initialBackoff: 500ms
        backoffFactor: 3
        maxRetries: 2
        jitter: true
    # Configuration for retrying reads.
    fetchRetry:
        initialBackoff: 500ms
        backoffFactor: 2
        maxRetries: 3
        jitter: true
    # Number of times we background health check for a node can fail before
    # considering the node unhealthy.
    backgroundHealthCheckFailLimit: 4
    backgroundHealthCheckFailThrottleFactor: 0.5

  # Sets GOGC value.
  gcPercentage: 100

  # Whether new series should be created asynchronously (recommended value
  # of true for high throughput.)
  writeNewSeriesAsync: true
  writeNewSeriesBackoffDuration: 2ms

  bootstrap:
    commitlog:
      # Whether tail end of corrupted commit logs cause an error on bootstrap.
      returnUnfulfilledForCorruptCommitLogFiles: false

  cache:
    # Caching policy for database blocks.
    series:
      policy: lru

  commitlog:
    # Maximum number of bytes that will be buffered before flushing the commitlog.
    flushMaxBytes: 524288
    # Maximum amount of time data can remain buffered before flushing the commitlog.
    flushEvery: 1s
    # Configuration for the commitlog queue. High throughput setups may require higher
    # values. Higher values will use more memory.
    queue:
      calculationType: fixed
      size: 2097152

  filesystem:
    # Directory to store M3DB data in.
    filePathPrefix: /opt/app/m3db/data
    # Various fixed-sized buffers used for M3DB I/O.
    writeBufferSize: 65536
    dataReadBufferSize: 65536
    infoReadBufferSize: 128
    seekReadBufferSize: 4096
    # Maximum Mib/s that can be written to disk by background operations like flushing
    # and snapshotting to prevent them from interfering with the commitlog. Increasing
    # this value can make node adds significantly faster if the underlyign disk can
    # support the throughput.
    throughputLimitMbps: 1000.0
    throughputCheckEvery: 128

  # This feature is currently not working, do not enable.
  repair:
    enabled: false
    throttle: 2m
    checkInterval: 1m

  # etcd configuration.
  discovery:
    config:
        service:
            # KV environment, zone, and service from which to write/read KV data (placement
            # and configuration). Leave these as the default values unless you know what
            # you're doing.
            env: default_env
            zone: embedded
            service: m3db
            # Directory to store cached etcd data in.
            cacheDir: /opt/app/m3db/m3kv
            # Configuration to identify the etcd hosts this node should connect to.
            etcdClusters:
                - zone: embedded
                  endpoints:
                      - 127.0.0.1:2379
        # Should only be present if running an M3DB cluster with embedded etcd.
        seedNodes:
            initialCluster:
                - hostID: m3db_local
                  endpoint: http://127.0.0.1:2380


```


# 集群版安装教程
> 过程
- https://m3db.io/docs/cluster/binaries_cluster/

